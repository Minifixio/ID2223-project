{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hopsworks\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "with open('../secrets/hopsworks_api_key.txt', 'r') as file:\n",
    "    HOPSWORKS_API_KEY = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_id.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_ID = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_secret.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_SECRET = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 18:10:07,864 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-09 18:10:07,880 INFO: Initializing external client\n",
      "2025-01-09 18:10:07,881 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-09 18:10:09,351 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1208515\n"
     ]
    }
   ],
   "source": [
    "# Connect to the project and feature store\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.data.iloc[idx]['user_id']\n",
    "        genre_embedding = self.data.iloc[idx]['genre_embedding']\n",
    "        artist_embedding = self.data.iloc[idx]['artist_embedding']\n",
    "        playlist_embedding = self.data.iloc[idx]['playlist_embedding']\n",
    "        return user_id, genre_embedding, artist_embedding, playlist_embedding\n",
    "\n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        # Separate processing for each embedding type\n",
    "        self.genre_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.artist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.playlist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        \n",
    "        # Joint Tower for final embedding\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(output_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, genre, artist, playlist):\n",
    "        genre_embed = self.genre_fc(genre)\n",
    "        artist_embed = self.artist_fc(artist)\n",
    "        playlist_embed = self.playlist_fc(playlist)\n",
    "        \n",
    "        # Concatenate embeddings and pass through final layers\n",
    "        combined = torch.cat([genre_embed, artist_embed, playlist_embed], dim=-1)\n",
    "        final_embed = self.fc_merge(combined)\n",
    "        return final_embed\n",
    "\n",
    "    def compute_similarity(self, query_embedding, database_embedding):\n",
    "        # Cosine similarity for comparison\n",
    "        return torch.nn.functional.cosine_similarity(query_embedding, database_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully! (0 dirs, 2 files)... DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the PyTorch model from the model registry\n",
    "model_registry = mr.get_model(\"two_tower_model_torch\", version=1)  # Adjust version as needed\n",
    "model_file_path = model_registry.download()\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(model_file_path, 'two_tower_model_torch.pth'))\n",
    "\n",
    "# Recreate the model architecture\n",
    "model = TwoTowerModel(\n",
    "    embedding_dim=checkpoint['embedding_dim'],\n",
    "    output_dim=checkpoint['output_dim']\n",
    ")\n",
    "\n",
    "# Load the state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.50s) \n",
      "2025-01-09 18:10:17,250 WARNING: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_embeddings_fg = fs.get_feature_group(name=\"spotify_user_embeddings\", version=2)\n",
    "user_embeddings_df = user_embeddings_fg.read()\n",
    "\n",
    "user_embeddings_df['genre_embedding'] = user_embeddings_df['genre_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['artist_embedding'] = user_embeddings_df['artist_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['playlist_embedding'] = user_embeddings_df['playlist_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['release_year_embedding'] = user_embeddings_df['release_year_embedding'].apply(lambda x: torch.tensor([x], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(genres, artists, model):\n",
    "    \"\"\"\n",
    "    Generate embeddings for genres and artists using a SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    # Combine genres and artists into a single list for embedding\n",
    "    inputs = genres + artists\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(inputs, show_progress_bar=True)\n",
    "    \n",
    "    # Split the embeddings back into genres and artists\n",
    "    genre_embeddings = embeddings[:len(genres)]\n",
    "    artist_embeddings = embeddings[len(genres):]\n",
    "    \n",
    "    return genre_embeddings, artist_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_embedding(user_playlists, transformer_model, top_artist_count, playlists_count):\n",
    "    print(\"Generating user embedding...\")\n",
    "    all_genres = []\n",
    "    all_artists = []\n",
    "    all_release_years = []\n",
    "    playlist_features = []\n",
    "\n",
    "    per_playlist_genre_embeddings = []  # Collect genre embeddings for each playlist\n",
    "\n",
    "    for playlist in user_playlists[:playlists_count]:  # Limit to first playlists_count playlists\n",
    "        # print(f\"Processing playlist: {playlist['name']}\")\n",
    "        playlist_name = playlist.get(\"name\", \"Unknown\")\n",
    "        playlist_id = playlist[\"id\"]\n",
    "\n",
    "        # Fetch tracks in the playlist\n",
    "        tracks = sp.playlist_tracks(playlist_id)[\"items\"]\n",
    "        # print(f\"Number of tracks: {len(tracks)}\")\n",
    "\n",
    "        genres = []\n",
    "        popularity = []\n",
    "        release_years = []\n",
    "        explicit_flags = []\n",
    "        artist_names = []\n",
    "        artist_ids = []\n",
    "\n",
    "        # Collect all artist IDs for batch processing\n",
    "        for item in tracks:\n",
    "            track = item[\"track\"]\n",
    "            if not track or track[\"is_local\"]:\n",
    "                continue\n",
    "            artist_ids.append(track[\"artists\"][0][\"id\"])  # Only taking the first artist for simplicity\n",
    "            release_date = track[\"album\"][\"release_date\"]\n",
    "\n",
    "            # Extract year from release date\n",
    "            release_year = release_date.split('-')[0]\n",
    "            release_years.append(int(release_year))\n",
    "\n",
    "            popularity.append(track.get(\"popularity\", 0))\n",
    "            explicit_flags.append(track.get(\"explicit\", False))\n",
    "\n",
    "        # Batch the artist IDs for the Get Several Artists API call\n",
    "        batch_size = 50\n",
    "        artist_info = []\n",
    "        for i in range(0, len(artist_ids), batch_size):\n",
    "            batch = artist_ids[i:i + batch_size]\n",
    "            response = sp.artists(batch)\n",
    "            artist_info.extend(response[\"artists\"])\n",
    "\n",
    "        # Process artist information\n",
    "        for artist in artist_info:\n",
    "            artist_name = artist.get(\"name\", \"Unknown\")\n",
    "            track_genres = artist.get(\"genres\", [])\n",
    "\n",
    "            artist_names.append(artist_name)\n",
    "            genres.extend(track_genres)\n",
    "\n",
    "        # Generate per-playlist genre embedding\n",
    "        if genres:\n",
    "            genre_embeddings = transformer_model.encode(genres, show_progress_bar=False)\n",
    "            playlist_genre_embedding = np.mean(genre_embeddings, axis=0)  # Average embedding for this playlist\n",
    "        else:\n",
    "            playlist_genre_embedding = np.zeros(384)\n",
    "\n",
    "        per_playlist_genre_embeddings.append(playlist_genre_embedding)\n",
    "\n",
    "        # Playlist-level features\n",
    "        playlist_features.append({\n",
    "            \"playlist_name\": playlist_name,\n",
    "            \"num_tracks\": len(tracks),\n",
    "            \"avg_popularity\": np.mean(popularity) if popularity else 0,\n",
    "            \"explicit_ratio\": np.mean(explicit_flags) if explicit_flags else 0\n",
    "        })\n",
    "\n",
    "        all_genres.extend(genres)\n",
    "        all_artists.extend(artist_names)\n",
    "        all_release_years.extend(release_years)\n",
    "\n",
    "    # Combine per-playlist genre embeddings using playlist sizes as weights\n",
    "    if per_playlist_genre_embeddings:\n",
    "        playlist_sizes = [p[\"num_tracks\"] for p in playlist_features]\n",
    "        playlist_weights = normalize(np.array(playlist_sizes).reshape(1, -1))[0]\n",
    "        playlist_embedding = np.sum(\n",
    "            [playlist_weights[i] * per_playlist_genre_embeddings[i] for i in range(len(per_playlist_genre_embeddings))],\n",
    "            axis=0\n",
    "        )\n",
    "    else:\n",
    "        playlist_embedding = np.zeros(384)\n",
    "\n",
    "    # Generate overall artist and genre embeddings\n",
    "    print(\"Generating contextual embeddings...\")\n",
    "\n",
    "    # Genre Embeddings\n",
    "    genre_embeddings = transformer_model.encode(all_genres, show_progress_bar=False) if all_genres else np.zeros((1, 384))\n",
    "    genre_embedding = np.mean(genre_embeddings, axis=0) if len(genre_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Artist Embeddings\n",
    "    artist_counter = Counter(all_artists)\n",
    "    top_artists = [artist for artist, _ in artist_counter.most_common(top_artist_count)]\n",
    "    artist_embeddings = transformer_model.encode(top_artists, show_progress_bar=False) if top_artists else np.zeros((1, 384))\n",
    "    artist_embedding = np.mean(artist_embeddings, axis=0) if len(artist_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Release year embedding\n",
    "    release_year_embedding = np.array([np.mean(all_release_years)]) if all_release_years else np.zeros(1)\n",
    "\n",
    "    print(\"User embedding generated successfully!\")\n",
    "    print(\"Genre embedding shape:\", genre_embedding.shape)\n",
    "    print(\"Artist embedding shape:\", artist_embedding.shape)\n",
    "    print(\"Playlist embedding shape:\", playlist_embedding.shape)\n",
    "    print(\"Release year embedding shape:\", release_year_embedding.shape)\n",
    "\n",
    "    # Return individual embeddings\n",
    "    return genre_embedding, artist_embedding, playlist_embedding, release_year_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def get_best_matching_users(user_id, transformer_model, top_artist_count, playlists_count, top_k):\n",
    "    # Fetch user playlists\n",
    "    playlists = sp.user_playlists(user_id)[\"items\"]\n",
    "    if not playlists:\n",
    "        print(f\"No playlists found for user {user_id}\")\n",
    "        return None\n",
    "\n",
    "    # Generate the user's embedding\n",
    "    genre_embedding, artist_embedding, playlist_embedding, release_year_embedding = generate_user_embedding(\n",
    "        playlists, transformer_model, top_artist_count, playlists_count\n",
    "    )\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    genre_embedding = torch.tensor(genre_embedding, dtype=torch.float)\n",
    "    artist_embedding = torch.tensor(artist_embedding, dtype=torch.float)\n",
    "    playlist_embedding = torch.tensor(playlist_embedding, dtype=torch.float)\n",
    "\n",
    "    print(\"User embeddings generated successfully!\")\n",
    "\n",
    "    model.eval()\n",
    "    top_k_indices = []\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(genre_embedding.unsqueeze(0), artist_embedding.unsqueeze(0), playlist_embedding.unsqueeze(0))\n",
    "        \n",
    "        # Compute embeddings for all database entries\n",
    "        db_genres = torch.stack(user_embeddings_df['genre_embedding'].tolist())\n",
    "        db_artists = torch.stack(user_embeddings_df['artist_embedding'].tolist())\n",
    "        db_playlists = torch.stack(user_embeddings_df['playlist_embedding'].tolist())\n",
    "        db_embeddings = model(db_genres, db_artists, db_playlists)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = torch.nn.functional.cosine_similarity(query_embedding, db_embeddings)\n",
    "        top_k_indices = torch.topk(similarities, k=top_k+1).indices\n",
    "        top_k_indices, similarities[top_k_indices]\n",
    "        scores = similarities[top_k_indices]\n",
    "\n",
    "        # Find user_id ID in the dataset and remove it from the top_k_indices\n",
    "        user_index = user_embeddings_df[user_embeddings_df['user_id'] == user_id].index[0]\n",
    "        index_to_delete = np.where(top_k_indices == user_index)[0][0]\n",
    "        top_k_indices = np.delete(top_k_indices, index_to_delete)\n",
    "        scores = np.delete(scores, index_to_delete)\n",
    "\n",
    "    # print(\"Top K Similar Embeddings:\", top_k_indices)\n",
    "    # print(\"Scores:\", scores)\n",
    "\n",
    "    return user_embeddings_df.iloc[top_k_indices], scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 18:10:20,707 INFO: Use pytorch device_name: mps\n",
      "2025-01-09 18:10:20,708 INFO: Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
      "Generating user embedding...\n",
      "2025-01-09 18:10:24,169 WARNING: DeprecationWarning: You should use `playlist_items(playlist_id, ...,additional_types=('track',))` instead\n",
      "\n",
      "Generating contextual embeddings...\n",
      "User embedding generated successfully!\n",
      "Genre embedding shape: (384,)\n",
      "Artist embedding shape: (384,)\n",
      "Playlist embedding shape: (384,)\n",
      "Release year embedding shape: (1,)\n",
      "User embeddings generated successfully!\n",
      "Top 5 similar users:\n",
      "zsuska_82 0.9920231699943542\n",
      "11182303216 0.9918758273124695\n",
      "ufmshw1g5mvuo04vs3bda3amp 0.991561770439148\n",
      "31qr5mtzfd3sdt5afqxthoyi7u5a 0.9897653460502625\n",
      "11179757726 0.9894211292266846\n"
     ]
    }
   ],
   "source": [
    "user_id = \"minifixiowow\"\n",
    "top_artist_count = 5\n",
    "playlists_count = 5\n",
    "\n",
    "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # You can replace this with another model if needed\n",
    "\n",
    "# Get the top K most similar users\n",
    "top_k = 5\n",
    "similar_users, similarity_scores = get_best_matching_users(user_id, transformer_model, top_artist_count, playlists_count, top_k)\n",
    "\n",
    "print(f\"Top {top_k} similar users:\")\n",
    "\n",
    "j = 0\n",
    "for i, row in similar_users.iterrows():\n",
    "    print(row.user_id, similarity_scores[j].item())\n",
    "    j += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
