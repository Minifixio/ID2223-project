{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hopsworks\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "with open('../secrets/hopsworks_api_key.txt', 'r') as file:\n",
    "    HOPSWORKS_API_KEY = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_id.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_ID = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_secret.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_SECRET = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:00:45,720 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-06 04:00:45,741 INFO: Initializing external client\n",
      "2025-01-06 04:00:45,741 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "\n",
      "Multiple projects found. \n",
      "\n",
      "\t (1) id2223_final_project\n",
      "\t (2) id2223_lab1_group9\n",
      "\t (3) lab1_mohamed_Emile\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter number corresponding to the project to use:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:00:50,183 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1208515\n"
     ]
    }
   ],
   "source": [
    "# Connect to the project and feature store\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully! (0 dirs, 1 files)... DONE\n"
     ]
    }
   ],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the Keras model from the model registry\n",
    "model_registry = mr.get_model(\"two_tower_recommender\", version=8)\n",
    "model_file_path = model_registry.download()\n",
    "model = tf.keras.models.load_model(\n",
    "    model_file_path + '/two_tower_model.keras',\n",
    "    custom_objects={\"Model\": Model}\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(genres, artists, model):\n",
    "    \"\"\"\n",
    "    Generate embeddings for genres and artists using a SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    # Combine genres and artists into a single list for embedding\n",
    "    inputs = genres + artists\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(inputs, show_progress_bar=True)\n",
    "    \n",
    "    # Split the embeddings back into genres and artists\n",
    "    genre_embeddings = embeddings[:len(genres)]\n",
    "    artist_embeddings = embeddings[len(genres):]\n",
    "    \n",
    "    return genre_embeddings, artist_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_embedding(user_playlists, transformer_model, top_artist_count, playlists_count):\n",
    "    print(\"Generating user embedding...\")\n",
    "    all_genres = []\n",
    "    all_artists = []\n",
    "    all_release_years = []\n",
    "    playlist_features = []\n",
    "\n",
    "    per_playlist_genre_embeddings = []  # Collect genre embeddings for each playlist\n",
    "\n",
    "    for playlist in user_playlists[:playlists_count]:  # Limit to first playlists_count playlists\n",
    "        # print(f\"Processing playlist: {playlist['name']}\")\n",
    "        playlist_name = playlist.get(\"name\", \"Unknown\")\n",
    "        playlist_id = playlist[\"id\"]\n",
    "\n",
    "        # Fetch tracks in the playlist\n",
    "        tracks = sp.playlist_tracks(playlist_id)[\"items\"]\n",
    "        # print(f\"Number of tracks: {len(tracks)}\")\n",
    "\n",
    "        genres = []\n",
    "        popularity = []\n",
    "        release_years = []\n",
    "        explicit_flags = []\n",
    "        artist_names = []\n",
    "        artist_ids = []\n",
    "\n",
    "        # Collect all artist IDs for batch processing\n",
    "        for item in tracks:\n",
    "            track = item[\"track\"]\n",
    "            if not track or track[\"is_local\"]:\n",
    "                continue\n",
    "            artist_ids.append(track[\"artists\"][0][\"id\"])  # Only taking the first artist for simplicity\n",
    "            release_date = track[\"album\"][\"release_date\"]\n",
    "\n",
    "            # Extract year from release date\n",
    "            release_year = release_date.split('-')[0]\n",
    "            release_years.append(int(release_year))\n",
    "\n",
    "            popularity.append(track.get(\"popularity\", 0))\n",
    "            explicit_flags.append(track.get(\"explicit\", False))\n",
    "\n",
    "        # Batch the artist IDs for the Get Several Artists API call\n",
    "        batch_size = 50\n",
    "        artist_info = []\n",
    "        for i in range(0, len(artist_ids), batch_size):\n",
    "            batch = artist_ids[i:i + batch_size]\n",
    "            response = sp.artists(batch)\n",
    "            artist_info.extend(response[\"artists\"])\n",
    "\n",
    "        # Process artist information\n",
    "        for artist in artist_info:\n",
    "            artist_name = artist.get(\"name\", \"Unknown\")\n",
    "            track_genres = artist.get(\"genres\", [])\n",
    "\n",
    "            artist_names.append(artist_name)\n",
    "            genres.extend(track_genres)\n",
    "\n",
    "        # Generate per-playlist genre embedding\n",
    "        if genres:\n",
    "            genre_embeddings = transformer_model.encode(genres, show_progress_bar=False)\n",
    "            playlist_genre_embedding = np.mean(genre_embeddings, axis=0)  # Average embedding for this playlist\n",
    "        else:\n",
    "            playlist_genre_embedding = np.zeros(384)\n",
    "\n",
    "        per_playlist_genre_embeddings.append(playlist_genre_embedding)\n",
    "\n",
    "        # Playlist-level features\n",
    "        playlist_features.append({\n",
    "            \"playlist_name\": playlist_name,\n",
    "            \"num_tracks\": len(tracks),\n",
    "            \"avg_popularity\": np.mean(popularity) if popularity else 0,\n",
    "            \"explicit_ratio\": np.mean(explicit_flags) if explicit_flags else 0\n",
    "        })\n",
    "\n",
    "        all_genres.extend(genres)\n",
    "        all_artists.extend(artist_names)\n",
    "        all_release_years.extend(release_years)\n",
    "\n",
    "    # Combine per-playlist genre embeddings using playlist sizes as weights\n",
    "    if per_playlist_genre_embeddings:\n",
    "        playlist_sizes = [p[\"num_tracks\"] for p in playlist_features]\n",
    "        playlist_weights = normalize(np.array(playlist_sizes).reshape(1, -1))[0]\n",
    "        playlist_embedding = np.sum(\n",
    "            [playlist_weights[i] * per_playlist_genre_embeddings[i] for i in range(len(per_playlist_genre_embeddings))],\n",
    "            axis=0\n",
    "        )\n",
    "    else:\n",
    "        playlist_embedding = np.zeros(384)\n",
    "\n",
    "    # Generate overall artist and genre embeddings\n",
    "    print(\"Generating contextual embeddings...\")\n",
    "\n",
    "    # Genre Embeddings\n",
    "    genre_embeddings = transformer_model.encode(all_genres, show_progress_bar=False) if all_genres else np.zeros((1, 384))\n",
    "    genre_embedding = np.mean(genre_embeddings, axis=0) if len(genre_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Artist Embeddings\n",
    "    artist_counter = Counter(all_artists)\n",
    "    top_artists = [artist for artist, _ in artist_counter.most_common(top_artist_count)]\n",
    "    artist_embeddings = transformer_model.encode(top_artists, show_progress_bar=False) if top_artists else np.zeros((1, 384))\n",
    "    artist_embedding = np.mean(artist_embeddings, axis=0) if len(artist_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Release year embedding\n",
    "    release_year_embedding = np.array([np.mean(all_release_years)]) if all_release_years else np.zeros(1)\n",
    "\n",
    "    print(\"User embedding generated successfully!\")\n",
    "    print(\"Genre embedding shape:\", genre_embedding.shape)\n",
    "    print(\"Artist embedding shape:\", artist_embedding.shape)\n",
    "    print(\"Playlist embedding shape:\", playlist_embedding.shape)\n",
    "    print(\"Release year embedding shape:\", release_year_embedding.shape)\n",
    "\n",
    "    # Return individual embeddings\n",
    "    return genre_embedding, artist_embedding, playlist_embedding, release_year_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def get_best_matching_user(user_id, transformer_model, top_artist_count, playlists_count):\n",
    "    # Fetch user playlists\n",
    "    playlists = sp.user_playlists(user_id)[\"items\"]\n",
    "    if not playlists:\n",
    "        print(f\"No playlists found for user {user_id}\")\n",
    "        return None\n",
    "\n",
    "    # Generate the user's embedding\n",
    "    genre_embedding, artist_embedding, playlist_embedding, release_year_embedding = generate_user_embedding(\n",
    "        playlists, transformer_model, top_artist_count, playlists_count\n",
    "    )\n",
    "\n",
    "    print(\"User embeddings generated successfully!\")\n",
    "\n",
    "    # Concatenate all embeddings into a single vector\n",
    "    user_embedding = np.concatenate([genre_embedding, artist_embedding, playlist_embedding, release_year_embedding])\n",
    "\n",
    "    # Get all user embeddings from the database (assuming these are already stored in the feature store)\n",
    "    user_embeddings_fg = fs.get_feature_group(name=\"spotify_user_embeddings\", version=2)\n",
    "    all_user_embeddings = user_embeddings_fg.read()\n",
    "\n",
    "    # Exclude the current user from the dataset\n",
    "    all_user_embeddings = all_user_embeddings[all_user_embeddings[\"user_id\"] != user_id]\n",
    "\n",
    "    all_user_embeddings['full_embedding'] = all_user_embeddings.apply(\n",
    "        lambda row: np.concatenate(\n",
    "            [row['genre_embedding'], row['artist_embedding'], row['playlist_embedding'], row['release_year_embedding']]\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    normalized_embeddings = normalize(np.array(all_user_embeddings['full_embedding'].tolist()))\n",
    "    all_user_embeddings['normalized_embedding'] = normalized_embeddings.tolist()\n",
    "\n",
    "    # Normalize all embeddings\n",
    "    normalized_user_embeddings = np.array(all_user_embeddings[\"normalized_embedding\"].tolist())\n",
    "    user_embedding_normalized = normalize(user_embedding.reshape(1, -1))\n",
    "\n",
    "    # Compute cosine similarity for all users\n",
    "    similarities = cosine_similarity(user_embedding_normalized, normalized_user_embeddings).flatten()\n",
    "\n",
    "    # Get the index of the most similar user\n",
    "    best_match_index = np.argmax(similarities)\n",
    "    best_match_user_id = all_user_embeddings.iloc[best_match_index][\"user_id\"]\n",
    "\n",
    "    return best_match_user_id, similarities[best_match_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:01:28,085 INFO: Use pytorch device_name: cpu\n",
      "2025-01-06 04:01:28,086 INFO: Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
      "Generating user embedding...\n",
      "Generating contextual embeddings...\n",
      "User embedding generated successfully!\n",
      "Genre embedding shape: (384,)\n",
      "Artist embedding shape: (384,)\n",
      "Playlist embedding shape: (384,)\n",
      "Release year embedding shape: (1,)\n",
      "User embeddings generated successfully!\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.40s) \n",
      "The best match for user minifixiowow is user zsuska_82 with a similarity score of 0.9999942084109562\n"
     ]
    }
   ],
   "source": [
    "user_id = \"minifixiowow\"\n",
    "top_artist_count = 5\n",
    "playlists_count = 5\n",
    "\n",
    "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # You can replace this with another model if needed\n",
    "\n",
    "best_match_user_id, similarity_score = get_best_matching_user(user_id, transformer_model, top_artist_count, playlists_count)\n",
    "\n",
    "print(f\"The best match for user {user_id} is user {best_match_user_id} with a similarity score of {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
