{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import re\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "with open('../secrets/hopsworks_api_key.txt', 'r') as file:\n",
    "    HOPSWORKS_API_KEY = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_id.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_ID = file.readline().strip()\n",
    "\n",
    "with open('../secrets/spotify_client_secret.txt', 'r') as file:\n",
    "    SPOTIFY_CLIENT_SECRET = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 19:37:23,852 INFO: Closing external client and cleaning up certificates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "2025-01-09 19:37:23,926 INFO: Initializing external client\n",
      "2025-01-09 19:37:23,927 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-09 19:37:25,510 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1208515\n"
     ]
    }
   ],
   "source": [
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.data.iloc[idx]['user_id']\n",
    "        genre_embedding = self.data.iloc[idx]['genre_embedding']\n",
    "        artist_embedding = self.data.iloc[idx]['artist_embedding']\n",
    "        playlist_embedding = self.data.iloc[idx]['playlist_embedding']\n",
    "        return user_id, genre_embedding, artist_embedding, playlist_embedding\n",
    "\n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        # Separate processing for each embedding type\n",
    "        self.genre_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.artist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.playlist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        \n",
    "        # Joint Tower for final embedding\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(output_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, genre, artist, playlist):\n",
    "        genre_embed = self.genre_fc(genre)\n",
    "        artist_embed = self.artist_fc(artist)\n",
    "        playlist_embed = self.playlist_fc(playlist)\n",
    "        \n",
    "        # Concatenate embeddings and pass through final layers\n",
    "        combined = torch.cat([genre_embed, artist_embed, playlist_embed], dim=-1)\n",
    "        final_embed = self.fc_merge(combined)\n",
    "        return final_embed\n",
    "\n",
    "    def compute_similarity(self, query_embedding, database_embedding):\n",
    "        # Cosine similarity for comparison\n",
    "        return torch.nn.functional.cosine_similarity(query_embedding, database_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully! (0 dirs, 2 files)... DONE\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the PyTorch model from the model registry\n",
    "model_registry = mr.get_model(\"two_tower_model_torch\", version=1)  # Adjust version as needed\n",
    "model_file_path = model_registry.download()\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(model_file_path, 'two_tower_model_torch.pth'))\n",
    "\n",
    "# Recreate the model architecture\n",
    "model = TwoTowerModel(\n",
    "    embedding_dim=checkpoint['embedding_dim'],\n",
    "    output_dim=checkpoint['output_dim']\n",
    ")\n",
    "\n",
    "# Load the state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 19:37:37,123 INFO: Use pytorch device_name: mps\n",
      "2025-01-09 19:37:37,123 INFO: Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # This can be replaced if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_embedding(user_playlists, transformer_model, top_artist_count, playlists_count):\n",
    "    print(\"Generating user embedding...\")\n",
    "    all_genres = []\n",
    "    all_artists = []\n",
    "    all_release_years = []\n",
    "    playlist_features = []\n",
    "\n",
    "    per_playlist_genre_embeddings = []  # Collect genre embeddings for each playlist\n",
    "\n",
    "    for playlist in user_playlists[:playlists_count]:  # Limit to first playlists_count playlists\n",
    "        # print(f\"Processing playlist: {playlist['name']}\")\n",
    "        playlist_name = playlist.get(\"name\", \"Unknown\")\n",
    "        playlist_id = playlist[\"id\"]\n",
    "\n",
    "        # Fetch tracks in the playlist\n",
    "        tracks = sp.playlist_tracks(playlist_id)[\"items\"]\n",
    "        # print(f\"Number of tracks: {len(tracks)}\")\n",
    "\n",
    "        genres = []\n",
    "        popularity = []\n",
    "        release_years = []\n",
    "        explicit_flags = []\n",
    "        artist_names = []\n",
    "        artist_ids = []\n",
    "\n",
    "        # Collect all artist IDs for batch processing\n",
    "        for item in tracks:\n",
    "            track = item[\"track\"]\n",
    "            if not track or track[\"is_local\"]:\n",
    "                continue\n",
    "            artist_ids.append(track[\"artists\"][0][\"id\"])  # Only taking the first artist for simplicity\n",
    "            release_date = track[\"album\"][\"release_date\"]\n",
    "\n",
    "            # Extract year from release date\n",
    "            release_year = release_date.split('-')[0]\n",
    "            release_years.append(int(release_year))\n",
    "\n",
    "            popularity.append(track.get(\"popularity\", 0))\n",
    "            explicit_flags.append(track.get(\"explicit\", False))\n",
    "\n",
    "        # Batch the artist IDs for the Get Several Artists API call\n",
    "        batch_size = 50\n",
    "        artist_info = []\n",
    "        for i in range(0, len(artist_ids), batch_size):\n",
    "            batch = artist_ids[i:i + batch_size]\n",
    "            response = sp.artists(batch)\n",
    "            artist_info.extend(response[\"artists\"])\n",
    "\n",
    "        # Process artist information\n",
    "        for artist in artist_info:\n",
    "            artist_name = artist.get(\"name\", \"Unknown\")\n",
    "            track_genres = artist.get(\"genres\", [])\n",
    "\n",
    "            artist_names.append(artist_name)\n",
    "            genres.extend(track_genres)\n",
    "\n",
    "        # Generate per-playlist genre embedding\n",
    "        if genres:\n",
    "            genre_embeddings = transformer_model.encode(genres, show_progress_bar=False)\n",
    "            playlist_genre_embedding = np.mean(genre_embeddings, axis=0)  # Average embedding for this playlist\n",
    "        else:\n",
    "            playlist_genre_embedding = np.zeros(384)\n",
    "\n",
    "        per_playlist_genre_embeddings.append(playlist_genre_embedding)\n",
    "\n",
    "        # Playlist-level features\n",
    "        playlist_features.append({\n",
    "            \"playlist_name\": playlist_name,\n",
    "            \"num_tracks\": len(tracks),\n",
    "            \"avg_popularity\": np.mean(popularity) if popularity else 0,\n",
    "            \"explicit_ratio\": np.mean(explicit_flags) if explicit_flags else 0\n",
    "        })\n",
    "\n",
    "        all_genres.extend(genres)\n",
    "        all_artists.extend(artist_names)\n",
    "        all_release_years.extend(release_years)\n",
    "\n",
    "    # Combine per-playlist genre embeddings using playlist sizes as weights\n",
    "    if per_playlist_genre_embeddings:\n",
    "        playlist_sizes = [p[\"num_tracks\"] for p in playlist_features]\n",
    "        playlist_weights = normalize(np.array(playlist_sizes).reshape(1, -1))[0]\n",
    "        playlist_embedding = np.sum(\n",
    "            [playlist_weights[i] * per_playlist_genre_embeddings[i] for i in range(len(per_playlist_genre_embeddings))],\n",
    "            axis=0\n",
    "        )\n",
    "    else:\n",
    "        playlist_embedding = np.zeros(384)\n",
    "\n",
    "    # Generate overall artist and genre embeddings\n",
    "    print(\"Generating contextual embeddings...\")\n",
    "\n",
    "    # Genre Embeddings\n",
    "    genre_embeddings = transformer_model.encode(all_genres, show_progress_bar=False) if all_genres else np.zeros((1, 384))\n",
    "    genre_embedding = np.mean(genre_embeddings, axis=0) if len(genre_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Artist Embeddings\n",
    "    artist_counter = Counter(all_artists)\n",
    "    top_artists = [artist for artist, _ in artist_counter.most_common(top_artist_count)]\n",
    "    artist_embeddings = transformer_model.encode(top_artists, show_progress_bar=False) if top_artists else np.zeros((1, 384))\n",
    "    artist_embedding = np.mean(artist_embeddings, axis=0) if len(artist_embeddings) > 0 else np.zeros(384)\n",
    "\n",
    "    # Release year embedding\n",
    "    release_year_embedding = np.array([np.mean(all_release_years)]) if all_release_years else np.zeros(1)\n",
    "\n",
    "    return genre_embedding, artist_embedding, playlist_embedding, release_year_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_id(spotify_url):\n",
    "    \"\"\"Extract the Spotify user ID from the URL.\"\"\"\n",
    "    match = re.search(r\"user/([^?]+)\", spotify_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_matching_users(user_id, user_embeddings_df, transformer_model, top_artist_count, playlists_count, top_k):\n",
    "    # Fetch user playlists\n",
    "    playlists = sp.user_playlists(user_id)[\"items\"]\n",
    "    if not playlists:\n",
    "        print(f\"No playlists found for user {user_id}\")\n",
    "        return None\n",
    "\n",
    "    # Generate the user's embedding\n",
    "    genre_embedding, artist_embedding, playlist_embedding, release_year_embedding = generate_user_embedding(\n",
    "        playlists, transformer_model, top_artist_count, playlists_count\n",
    "    )\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    genre_embedding = torch.tensor(genre_embedding, dtype=torch.float)\n",
    "    artist_embedding = torch.tensor(artist_embedding, dtype=torch.float)\n",
    "    playlist_embedding = torch.tensor(playlist_embedding, dtype=torch.float)\n",
    "\n",
    "    print(\"User embeddings generated successfully!\")\n",
    "\n",
    "    model.eval()\n",
    "    top_k_indices = []\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(genre_embedding.unsqueeze(0), artist_embedding.unsqueeze(0), playlist_embedding.unsqueeze(0))\n",
    "        \n",
    "        # Compute embeddings for all database entries\n",
    "        db_genres = torch.stack(user_embeddings_df['genre_embedding'].tolist())\n",
    "        db_artists = torch.stack(user_embeddings_df['artist_embedding'].tolist())\n",
    "        db_playlists = torch.stack(user_embeddings_df['playlist_embedding'].tolist())\n",
    "        db_embeddings = model(db_genres, db_artists, db_playlists)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = torch.nn.functional.cosine_similarity(query_embedding, db_embeddings)\n",
    "        top_k_indices = torch.topk(similarities, k=top_k+1).indices\n",
    "        top_k_indices, similarities[top_k_indices]\n",
    "        scores = similarities[top_k_indices]\n",
    "\n",
    "        # Find user_id ID in the dataset and remove it from the top_k_indices\n",
    "        user_index = user_embeddings_df[user_embeddings_df['user_id'] == user_id].index[0]\n",
    "        index_to_delete = np.where(top_k_indices == user_index)[0][0]\n",
    "        top_k_indices = np.delete(top_k_indices, index_to_delete)\n",
    "        scores = np.delete(scores, index_to_delete)\n",
    "\n",
    "    return user_embeddings_df.iloc[top_k_indices], scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_users(spotify_url, top_artist_count, playlists_count, progress=gr.Progress(track_tqdm=True)):\n",
    "    user_id = spotify_url\n",
    "    if not user_id:\n",
    "        return \"Invalid Spotify profile URL.\"\n",
    "\n",
    "    try:\n",
    "        # Step 1: Gathering profile data\n",
    "        progress(0, desc=\"Gathering profile data\")\n",
    "        print(\"Gathering profile data...\")\n",
    "        playlists = sp.user_playlists(user_id)[\"items\"]\n",
    "        \n",
    "        if not playlists:\n",
    "            return f\"No playlists found for user {user_id}.\"\n",
    "\n",
    "        # Step 2: Computing the best candidates\n",
    "        progress(0.2, desc=\"Generating user embeddings\")\n",
    "        print(\"Generating user embeddings...\")\n",
    "\n",
    "        genre_embedding, artist_embedding, playlist_embedding, release_year_embedding = generate_user_embedding(\n",
    "            playlists, transformer_model, top_artist_count, playlists_count\n",
    "        )\n",
    "\n",
    "        # Add the user's embedding to Hopsworks\n",
    "        print(\"Adding the user's embedding to Hopsworks...\")\n",
    "        user_embedding_dict = {\n",
    "            \"user_id\": user_id,\n",
    "            \"genre_embedding\": genre_embedding.tolist(),\n",
    "            \"artist_embedding\": artist_embedding.tolist(),\n",
    "            \"playlist_embedding\": playlist_embedding.tolist(),\n",
    "            \"release_year_embedding\": release_year_embedding.tolist()\n",
    "        }\n",
    "        user_embedding_df = pd.DataFrame([user_embedding_dict])  # Create a DataFrame with a single row\n",
    "\n",
    "        # Insert into the feature store\n",
    "        feature_store = project.get_feature_store()\n",
    "        feature_group = feature_store.get_feature_group(name=\"spotify_user_embeddings\", version=2)\n",
    "        feature_group.insert(user_embedding_df)\n",
    "        print(f\"User embedding for {user_id} added to Hopsworks successfully.\")\n",
    "\n",
    "        # Get all user embeddings from the database (assuming these are already stored in the feature store)\n",
    "        user_embeddings_fg = fs.get_feature_group(name=\"spotify_user_embeddings\", version=2)\n",
    "        user_embeddings_df = user_embeddings_fg.read()\n",
    "\n",
    "        # Exclude the current user from the dataset\n",
    "        user_embeddings_df = user_embeddings_df[user_embeddings_df[\"user_id\"] != user_id]\n",
    "        user_embeddings_df = user_embeddings_fg.read()\n",
    "\n",
    "        user_embeddings_df['genre_embedding'] = user_embeddings_df['genre_embedding'].apply(\n",
    "            lambda x: torch.tensor(x, dtype=torch.float)\n",
    "        )\n",
    "        user_embeddings_df['artist_embedding'] = user_embeddings_df['artist_embedding'].apply(\n",
    "            lambda x: torch.tensor(x, dtype=torch.float)\n",
    "        )\n",
    "        user_embeddings_df['playlist_embedding'] = user_embeddings_df['playlist_embedding'].apply(\n",
    "            lambda x: torch.tensor(x, dtype=torch.float)\n",
    "        )\n",
    "        user_embeddings_df['release_year_embedding'] = user_embeddings_df['release_year_embedding'].apply(lambda x: torch.tensor([x], dtype=torch.float))\n",
    "\n",
    "        # Compute cosine similarity for all users\n",
    "        top_k = 5\n",
    "        similar_users, similarity_scores = get_best_matching_users(user_id, user_embeddings_df, transformer_model, top_artist_count, playlists_count, top_k)\n",
    "\n",
    "        # Finding the top matches\n",
    "        progress(0.9, desc=\"Finding matches\")\n",
    "        results = []\n",
    "        \n",
    "        j = 0\n",
    "        for i, row in similar_users.iterrows():\n",
    "            matched_user_id = row.user_id\n",
    "            matched_similarity = similarity_scores[j].item()\n",
    "            print(f\"User ID: {matched_user_id}, Similarity: {matched_similarity:.5f}\")\n",
    "\n",
    "            try:\n",
    "                matched_profile = sp.user(matched_user_id)                \n",
    "                # Check for profile picture; if none, use default\n",
    "                profile_pic = matched_profile.get(\"images\", [{}])[0].get(\"url\", \"https://upload.wikimedia.org/wikipedia/commons/a/ac/Default_pfp.jpg\")  # Default image URL\n",
    "                display_name = matched_profile.get(\"display_name\", \"Unknown User\")\n",
    "                profile_url = matched_profile.get(\"external_urls\", {}).get(\"spotify\", \"#\")\n",
    "                \n",
    "                results.append({\n",
    "                    \"profile_pic\": profile_pic,\n",
    "                    \"display_name\": display_name,\n",
    "                    \"profile_url\": profile_url,\n",
    "                    \"similarity\": matched_similarity\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching profile: {e}\")\n",
    "            \n",
    "            j += 1\n",
    "\n",
    "        # Formatting results\n",
    "        progress(0.95, desc=\"Formatting results\")\n",
    "        output = []\n",
    "        for result in results:\n",
    "            if result[\"profile_pic\"]:\n",
    "                img_tag = f'<img src=\"{result[\"profile_pic\"]}\" alt=\"Profile Picture\" width=\"100\" height=\"100\">'\n",
    "            else:\n",
    "                img_tag = \"<img src='https://upload.wikimedia.org/wikipedia/commons/a/ac/Default_pfp.jpg' alt='Default Profile Picture' width='100' height='100'>\"  # Default image\n",
    "            link_tag = f'<a href=\"{result[\"profile_url\"]}\" target=\"_blank\">{result[\"display_name\"]}</a>'\n",
    "            similarity_tag = f\" (Similarity: {result['similarity']})\"\n",
    "            output.append(f\"{img_tag} {link_tag} {similarity_tag}\")\n",
    "\n",
    "        progress(1.0, desc=\"Complete\")\n",
    "        return \"<br>\".join(output)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing request: {str(e)}\")\n",
    "        return f\"Error processing request: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 19:40:27,158 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Create the Gradio UI\n",
    "playlists_count = 5\n",
    "top_artist_count = 10\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=recommend_users,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Spotify Profile URL\"),  # For the user's Spotify URL\n",
    "        gr.Slider(minimum=1, maximum=10, step=1, value=5, label=\"Top Artist Count\"),  # For top artist count\n",
    "        gr.Slider(minimum=1, maximum=20, step=1, value=5, label=\"Playlists Count\")  # For playlists count\n",
    "    ],\n",
    "    outputs=gr.HTML(label=\"Recommended Spotify Profiles\"),\n",
    "    title=\"Spotify Profile Recommender\",\n",
    "    description=\"Enter your Spotify profile URL to find the most similar users based on your playlists!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "2025-01-09 19:40:28,481 INFO: HTTP Request: GET http://127.0.0.1:7864/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-01-09 19:40:28,488 INFO: HTTP Request: HEAD http://127.0.0.1:7864/ \"HTTP/1.1 200 OK\"\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering profile data...\n",
      "Generating user embeddings...\n",
      "Generating user embedding...\n",
      "2025-01-09 19:40:34,390 WARNING: DeprecationWarning: You should use `playlist_items(playlist_id, ...,additional_types=('track',))` instead\n",
      "\n",
      "Generating contextual embeddings...\n",
      "Adding the user's embedding to Hopsworks...\n",
      "Launching job: spotify_user_embeddings_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1208515/jobs/named/spotify_user_embeddings_2_offline_fg_materialization/executions\n",
      "User embedding for minifixiowow added to Hopsworks successfully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.08s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.84s) \n",
      "Generating user embedding...\n",
      "2025-01-09 19:40:54,522 WARNING: DeprecationWarning: You should use `playlist_items(playlist_id, ...,additional_types=('track',))` instead\n",
      "\n",
      "Generating contextual embeddings...\n",
      "User embeddings generated successfully!\n",
      "User ID: 0rtyn4wld42peqkhmxijmeuaw, Similarity: 0.99498\n",
      "User ID: tns1gewp6t12hxh2fxiooxrun, Similarity: 0.99495\n",
      "User ID: 12178095060, Similarity: 0.99394\n",
      "User ID: ufmshw1g5mvuo04vs3bda3amp, Similarity: 0.99378\n",
      "User ID: bxqwe6rlmy5r2w5recq40nmjn, Similarity: 0.99332\n"
     ]
    }
   ],
   "source": [
    "# Launch the app\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
