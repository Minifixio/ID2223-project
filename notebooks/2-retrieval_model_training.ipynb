{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('HOPSWORKS_API_KEY') is not None:\n",
    "    HOPSWORKS_API_KEY = os.getenv('HOPSWORKS_API_KEY')\n",
    "else:\n",
    "    with open('../secrets/hopsworks_api_key.txt', 'r') as file:\n",
    "        HOPSWORKS_API_KEY = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:55:24,013 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-09 16:55:24,027 INFO: Initializing external client\n",
      "2025-01-09 16:55:24,027 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-09 16:55:25,423 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1208515\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.88s) \n",
      "A total of 103 user embeddings are available.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>genre_embedding</th>\n",
       "      <th>artist_embedding</th>\n",
       "      <th>playlist_embedding</th>\n",
       "      <th>release_year_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31imc4msmvetbl26gly5n55jbkka</td>\n",
       "      <td>[0.1219930648803711, 0.1214483454823494, -0.27...</td>\n",
       "      <td>[0.28332215547561646, -0.15212738513946533, -0...</td>\n",
       "      <td>[0.1219930648803711, 0.1214483454823494, -0.27...</td>\n",
       "      <td>[2018.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31tgsl3dejcqihle3pv7o6eeng2a</td>\n",
       "      <td>[-0.3863714933395386, -0.5621631145477295, 0.1...</td>\n",
       "      <td>[0.3942939341068268, -0.33002883195877075, 0.3...</td>\n",
       "      <td>[-0.7064403295516968, -0.9494979381561279, 0.1...</td>\n",
       "      <td>[2019.9066666666668]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31fg5ma4zjh37mcqzto3xt2sxc3a</td>\n",
       "      <td>[-0.31446775794029236, -0.2531762421131134, 0....</td>\n",
       "      <td>[-0.29996415972709656, 0.5447441339492798, 0.0...</td>\n",
       "      <td>[-0.31446775794029236, -0.2531762421131134, 0....</td>\n",
       "      <td>[2019.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31h7ml3xiavflj5n7d4av5u5xaie</td>\n",
       "      <td>[-0.3711507022380829, -0.19814574718475342, -0...</td>\n",
       "      <td>[-0.09817744046449661, 0.1808864027261734, -0....</td>\n",
       "      <td>[-0.5167202949523926, -0.22468358278274536, -0...</td>\n",
       "      <td>[2019.8850574712644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31frxab22c2ez34gnfggtqqsnope</td>\n",
       "      <td>[0.14112409949302673, 0.12898339331150055, -0....</td>\n",
       "      <td>[-0.010701656341552734, 0.32390376925468445, -...</td>\n",
       "      <td>[0.26713827252388, 0.21868111193180084, -0.577...</td>\n",
       "      <td>[2017.2272727272727]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id  \\\n",
       "0  31imc4msmvetbl26gly5n55jbkka   \n",
       "1  31tgsl3dejcqihle3pv7o6eeng2a   \n",
       "2  31fg5ma4zjh37mcqzto3xt2sxc3a   \n",
       "3  31h7ml3xiavflj5n7d4av5u5xaie   \n",
       "4  31frxab22c2ez34gnfggtqqsnope   \n",
       "\n",
       "                                     genre_embedding  \\\n",
       "0  [0.1219930648803711, 0.1214483454823494, -0.27...   \n",
       "1  [-0.3863714933395386, -0.5621631145477295, 0.1...   \n",
       "2  [-0.31446775794029236, -0.2531762421131134, 0....   \n",
       "3  [-0.3711507022380829, -0.19814574718475342, -0...   \n",
       "4  [0.14112409949302673, 0.12898339331150055, -0....   \n",
       "\n",
       "                                    artist_embedding  \\\n",
       "0  [0.28332215547561646, -0.15212738513946533, -0...   \n",
       "1  [0.3942939341068268, -0.33002883195877075, 0.3...   \n",
       "2  [-0.29996415972709656, 0.5447441339492798, 0.0...   \n",
       "3  [-0.09817744046449661, 0.1808864027261734, -0....   \n",
       "4  [-0.010701656341552734, 0.32390376925468445, -...   \n",
       "\n",
       "                                  playlist_embedding release_year_embedding  \n",
       "0  [0.1219930648803711, 0.1214483454823494, -0.27...               [2018.0]  \n",
       "1  [-0.7064403295516968, -0.9494979381561279, 0.1...   [2019.9066666666668]  \n",
       "2  [-0.31446775794029236, -0.2531762421131134, 0....               [2019.0]  \n",
       "3  [-0.5167202949523926, -0.22468358278274536, -0...   [2019.8850574712644]  \n",
       "4  [0.26713827252388, 0.21868111193180084, -0.577...   [2017.2272727272727]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings_fg = fs.get_feature_group(\n",
    "    name='spotify_user_embeddings',\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "user_embeddings_df = user_embeddings_fg.read()\n",
    "print(f\"A total of {len(user_embeddings_df)} user embeddings are available.\")\n",
    "user_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_df['genre_embedding'] = user_embeddings_df['genre_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['artist_embedding'] = user_embeddings_df['artist_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['playlist_embedding'] = user_embeddings_df['playlist_embedding'].apply(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float)\n",
    ")\n",
    "user_embeddings_df['release_year_embedding'] = user_embeddings_df['release_year_embedding'].apply(lambda x: torch.tensor([x], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.data.iloc[idx]['user_id']\n",
    "        genre_embedding = self.data.iloc[idx]['genre_embedding']\n",
    "        artist_embedding = self.data.iloc[idx]['artist_embedding']\n",
    "        playlist_embedding = self.data.iloc[idx]['playlist_embedding']\n",
    "        return user_id, genre_embedding, artist_embedding, playlist_embedding\n",
    "\n",
    "\n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        # Separate processing for each embedding type\n",
    "        self.genre_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.artist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        self.playlist_fc = Tower(input_dim=embedding_dim, output_dim=output_dim)\n",
    "        \n",
    "        # Joint Tower for final embedding\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(output_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, genre, artist, playlist):\n",
    "        genre_embed = self.genre_fc(genre)\n",
    "        artist_embed = self.artist_fc(artist)\n",
    "        playlist_embed = self.playlist_fc(playlist)\n",
    "        \n",
    "        # Concatenate embeddings and pass through final layers\n",
    "        combined = torch.cat([genre_embed, artist_embed, playlist_embed], dim=-1)\n",
    "        final_embed = self.fc_merge(combined)\n",
    "        return final_embed\n",
    "\n",
    "    def compute_similarity(self, query_embedding, database_embedding):\n",
    "        # Cosine similarity for comparison\n",
    "        return torch.nn.functional.cosine_similarity(query_embedding, database_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n",
      "Epoch 1, Loss: 0.10138204880058765\n",
      "Epoch 2, Loss: 0.10017404519021511\n",
      "Epoch 3, Loss: 0.10527209378778934\n",
      "Epoch 4, Loss: 0.11186422407627106\n",
      "Epoch 5, Loss: 0.10186378099024296\n",
      "Epoch 6, Loss: 0.10617948696017265\n",
      "Epoch 7, Loss: 0.10847200080752373\n",
      "Epoch 8, Loss: 0.09544013813138008\n",
      "Epoch 9, Loss: 0.10728724673390388\n",
      "Epoch 10, Loss: 0.10205137729644775\n",
      "Epoch 11, Loss: 0.1012562494724989\n",
      "Epoch 12, Loss: 0.10761732049286366\n",
      "Epoch 13, Loss: 0.1081188227981329\n",
      "Epoch 14, Loss: 0.09446662850677967\n",
      "Epoch 15, Loss: 0.09733587689697742\n",
      "Epoch 16, Loss: 0.10303829237818718\n",
      "Epoch 17, Loss: 0.1010410264134407\n",
      "Epoch 18, Loss: 0.098635733127594\n",
      "Epoch 19, Loss: 0.1026865802705288\n",
      "Epoch 20, Loss: 0.1125249769538641\n",
      "Epoch 21, Loss: 0.10133769921958447\n",
      "Epoch 22, Loss: 0.10164368152618408\n",
      "Epoch 23, Loss: 0.09949316270649433\n",
      "Epoch 24, Loss: 0.10471094958484173\n",
      "Epoch 25, Loss: 0.10842087119817734\n",
      "Epoch 26, Loss: 0.1072970312088728\n",
      "Epoch 27, Loss: 0.10007558017969131\n",
      "Epoch 28, Loss: 0.10881122574210167\n",
      "Epoch 29, Loss: 0.10432787053287029\n",
      "Epoch 30, Loss: 0.11182460188865662\n",
      "Epoch 31, Loss: 0.10665151104331017\n",
      "Epoch 32, Loss: 0.1057069581001997\n",
      "Epoch 33, Loss: 0.10838332958519459\n",
      "Epoch 34, Loss: 0.11300871148705482\n",
      "Epoch 35, Loss: 0.10415762849152088\n",
      "Epoch 36, Loss: 0.10028758831322193\n",
      "Epoch 37, Loss: 0.09807111322879791\n",
      "Epoch 38, Loss: 0.09906571544706821\n",
      "Epoch 39, Loss: 0.10815552622079849\n",
      "Epoch 40, Loss: 0.10955098457634449\n",
      "Epoch 41, Loss: 0.10074399039149284\n",
      "Epoch 42, Loss: 0.09678026847541332\n",
      "Epoch 43, Loss: 0.10668769665062428\n",
      "Epoch 44, Loss: 0.10343638248741627\n",
      "Epoch 45, Loss: 0.11408349312841892\n",
      "Epoch 46, Loss: 0.11501804366707802\n",
      "Epoch 47, Loss: 0.09836717322468758\n",
      "Epoch 48, Loss: 0.0937258992344141\n",
      "Epoch 49, Loss: 0.11045981757342815\n",
      "Epoch 50, Loss: 0.10345255024731159\n",
      "Epoch 51, Loss: 0.10296139307320118\n",
      "Epoch 52, Loss: 0.10077698342502117\n",
      "Epoch 53, Loss: 0.12196685373783112\n",
      "Epoch 54, Loss: 0.11808392032980919\n",
      "Epoch 55, Loss: 0.1074204109609127\n",
      "Epoch 56, Loss: 0.11230438761413097\n",
      "Epoch 57, Loss: 0.09918207488954067\n",
      "Epoch 58, Loss: 0.10946067981421947\n",
      "Epoch 59, Loss: 0.10593205317854881\n",
      "Epoch 60, Loss: 0.11522838659584522\n",
      "Epoch 61, Loss: 0.10655758157372475\n",
      "Epoch 62, Loss: 0.1073002852499485\n",
      "Epoch 63, Loss: 0.10308783128857613\n",
      "Epoch 64, Loss: 0.11486334726214409\n",
      "Epoch 65, Loss: 0.1034904420375824\n",
      "Epoch 66, Loss: 0.10250802338123322\n",
      "Epoch 67, Loss: 0.11209829151630402\n",
      "Epoch 68, Loss: 0.09632873348891735\n",
      "Epoch 69, Loss: 0.10792535543441772\n",
      "Epoch 70, Loss: 0.09954957291483879\n",
      "Epoch 71, Loss: 0.11070135980844498\n",
      "Epoch 72, Loss: 0.0965745560824871\n",
      "Epoch 73, Loss: 0.10193807445466518\n",
      "Epoch 74, Loss: 0.10936625115573406\n",
      "Epoch 75, Loss: 0.0985727459192276\n",
      "Epoch 76, Loss: 0.0997143592685461\n",
      "Epoch 77, Loss: 0.10276993177831173\n",
      "Epoch 78, Loss: 0.10455000586807728\n",
      "Epoch 79, Loss: 0.1230209432542324\n",
      "Epoch 80, Loss: 0.10104133374989033\n",
      "Epoch 81, Loss: 0.1076880693435669\n",
      "Epoch 82, Loss: 0.10646357573568821\n",
      "Epoch 83, Loss: 0.09920582361519337\n",
      "Epoch 84, Loss: 0.10157820954918861\n",
      "Epoch 85, Loss: 0.10075056180357933\n",
      "Epoch 86, Loss: 0.11165952309966087\n",
      "Epoch 87, Loss: 0.10308982990682125\n",
      "Epoch 88, Loss: 0.10056430846452713\n",
      "Epoch 89, Loss: 0.10541554540395737\n",
      "Epoch 90, Loss: 0.11056863889098167\n",
      "Epoch 91, Loss: 0.09972951747477055\n",
      "Epoch 92, Loss: 0.11660090461373329\n",
      "Epoch 93, Loss: 0.10309610888361931\n",
      "Epoch 94, Loss: 0.1141415610909462\n",
      "Epoch 95, Loss: 0.10307800769805908\n",
      "Epoch 96, Loss: 0.10307422839105129\n",
      "Epoch 97, Loss: 0.10141975432634354\n",
      "Epoch 98, Loss: 0.10885303281247616\n",
      "Epoch 99, Loss: 0.11245645210146904\n",
      "Epoch 100, Loss: 0.11247368343174458\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "df = user_embeddings_df\n",
    "print(df['genre_embedding'][0].shape)\n",
    "embedding_dim = len(df['genre_embedding'][0])  # Assuming all embeddings have the same dimension\n",
    "output_dim = 64\n",
    "margin = 0.5\n",
    "\n",
    "model = TwoTowerModel(embedding_dim=embedding_dim, output_dim=output_dim)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1/10e8, weight_decay=1e-5)\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "train_dataset = EmbeddingDataset(df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Dummy negative sampling (replace with actual negatives)\n",
    "def negative_sample(batch_size, df):\n",
    "    # Randomly sample other embeddings as negatives\n",
    "    sampled = df.sample(batch_size)  # Ensure the sample size matches the batch size\n",
    "    return torch.stack(sampled['genre_embedding'].tolist()), \\\n",
    "           torch.stack(sampled['artist_embedding'].tolist()), \\\n",
    "           torch.stack(sampled['playlist_embedding'].tolist())\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for user_ids, genres, artists, playlists in train_loader:\n",
    "        # Ensure embeddings are converted to tensors\n",
    "        genres = torch.tensor(genres.tolist(), dtype=torch.float32)\n",
    "        artists = torch.tensor(artists.tolist(), dtype=torch.float32)\n",
    "        playlists = torch.tensor(playlists.tolist(), dtype=torch.float32)\n",
    "        \n",
    "        # Generate negative samples\n",
    "        neg_genres, neg_artists, neg_playlists = negative_sample(len(genres), df)\n",
    "        \n",
    "        # Forward pass for positives and negatives\n",
    "        positive_embed = model(genres, artists, playlists)\n",
    "        negative_embed = model(neg_genres, neg_artists, neg_playlists)\n",
    "        \n",
    "        # Create labels for the current batch size\n",
    "        labels = torch.ones(positive_embed.size(0))\n",
    "        \n",
    "        # Calculate loss - note we're using just one pair of embeddings and their labels\n",
    "        loss = criterion(positive_embed, negative_embed, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Genre: tensor([-3.8637e-01, -5.6216e-01,  1.0338e-01, -7.3647e-01, -7.5121e-02,\n",
      "        -1.8782e-01,  7.2601e-01, -1.2636e-02,  7.3718e-02, -9.2311e-02,\n",
      "         4.3279e-01,  4.2068e-02,  2.1213e-01, -2.1270e-01,  7.8436e-01,\n",
      "         1.4410e-02, -7.2733e-02,  2.3834e-02,  8.1407e-03, -1.0196e-01,\n",
      "         8.8158e-02, -4.7116e-01, -6.8120e-02, -2.5079e-01, -5.2755e-01,\n",
      "         1.5192e-01, -3.5234e-01,  1.0232e-01, -2.9904e-02,  3.3438e-02,\n",
      "         4.5600e-01,  5.3486e-01,  3.5856e-01, -3.2005e-01, -2.5237e-01,\n",
      "         3.1210e-01, -3.8644e-01,  2.0192e-01, -1.3462e-01, -3.3583e-01,\n",
      "        -1.9587e-01, -4.2149e-01, -5.4331e-02, -1.1561e-01, -3.0111e-03,\n",
      "        -2.6216e-02, -2.1129e-01,  4.2811e-01,  3.5764e-02,  4.4356e-01,\n",
      "        -5.7137e-02, -3.7648e-01, -2.0451e-01,  2.4443e-01, -1.5736e-01,\n",
      "         3.3731e-02,  9.0493e-02,  5.0966e-01,  3.8582e-01,  3.7211e-01,\n",
      "        -5.0354e-01, -7.1162e-02, -5.4695e-01,  6.1910e-01, -6.1478e-01,\n",
      "         5.2007e-02, -3.4706e-01, -1.0533e-01, -8.0306e-02, -6.0604e-01,\n",
      "         1.5318e-01, -2.5811e-01,  2.1575e-01,  1.9761e-01,  2.1159e-02,\n",
      "         7.5385e-02, -5.9418e-01, -1.7511e-01, -5.4842e-01,  3.5748e-01,\n",
      "         5.8861e-01, -6.6800e-02, -1.1865e-01, -3.4501e-01, -2.4770e-01,\n",
      "         7.9869e-02,  3.4522e-01,  4.6021e-01,  6.5347e-02,  1.9410e-02,\n",
      "        -3.7656e-01,  8.9660e-01,  5.4416e-02,  3.2088e-01,  1.9062e-01,\n",
      "         2.9249e-01, -4.2014e-01, -1.1704e+00, -5.0183e-02,  1.4117e+00,\n",
      "        -1.7041e-01,  2.6347e-01, -1.8447e-02,  3.6902e-01,  2.5259e-01,\n",
      "        -6.3993e-01, -7.4153e-02,  1.3012e-01,  2.2395e-01,  4.0380e-01,\n",
      "        -1.8475e-01,  8.1095e-02,  2.6081e-01, -2.7285e-01, -2.3821e-01,\n",
      "        -4.0178e-01,  2.1471e-01, -2.2993e-01,  2.9738e-01, -5.2606e-01,\n",
      "         5.7390e-01, -1.3842e-01, -4.5322e-01, -1.2438e-01,  2.6194e-01,\n",
      "         7.9449e-03,  3.8470e-01,  4.1527e-01, -3.4756e-01,  2.8547e-01,\n",
      "        -1.7477e-02,  1.3033e-03,  1.1098e-02,  1.3898e-01, -2.5329e-01,\n",
      "        -9.3577e-02, -5.2132e-01, -7.3497e-02,  2.5817e-02, -3.5514e-01,\n",
      "        -4.3336e-01, -6.3829e-02, -2.5441e-01, -4.2551e-01,  1.5168e-01,\n",
      "         1.0956e-01, -2.2393e-01, -3.5110e-01, -2.6427e-01,  2.5884e-01,\n",
      "         1.5010e-01, -1.8291e-01, -7.3599e-02,  5.5339e-01, -1.6280e-01,\n",
      "         5.9789e-02,  7.0692e-01,  2.0869e-01,  3.5938e-01, -3.3224e-01,\n",
      "        -2.9773e-01, -3.2308e-01,  7.7160e-01,  1.6003e-02, -1.1319e-01,\n",
      "        -5.2285e-01,  2.0074e-02,  1.9895e-01, -2.0469e-01, -4.2387e-02,\n",
      "         7.4344e-04,  1.7124e-01, -2.6765e-01, -1.1203e-01, -3.1035e-01,\n",
      "         2.3939e-01,  2.0050e-01,  2.3943e-01,  3.5712e-01,  2.2561e-01,\n",
      "        -5.8161e-01,  1.5660e-01,  3.3617e-01,  4.6031e-01, -5.3356e-01,\n",
      "         1.0516e-01,  3.1665e-01,  1.0732e-01,  1.3735e-01, -3.7371e-02,\n",
      "         2.2747e-01, -7.5063e-01,  4.1140e-01, -8.1725e-02,  7.8175e-02,\n",
      "        -6.3888e-02, -1.5557e-02,  1.8507e-01,  3.6216e-01, -2.7091e-01,\n",
      "        -4.0900e-01, -3.1310e-01, -3.3300e-01, -2.5464e-01,  6.8185e-01,\n",
      "         4.2514e-01,  4.9745e-01,  6.4957e-02,  2.8106e-01, -4.1372e-01,\n",
      "         3.3377e-02, -6.5044e-01,  7.2737e-02,  8.3661e-02, -5.3167e-02,\n",
      "        -5.9248e-01, -1.0085e-01, -1.0707e-01, -6.2612e-01,  2.3664e-01,\n",
      "        -6.7511e-01, -2.7525e-02, -1.6329e-01, -4.2848e-01, -4.2507e-01,\n",
      "        -1.9586e-01, -2.7823e-01,  5.3861e-01, -4.4870e-02,  9.4794e-02,\n",
      "        -2.2002e-01,  1.6595e-01,  6.2916e-01,  2.3648e-01, -5.3229e-01,\n",
      "         3.1659e-01, -1.0501e-01,  2.9344e-01, -2.4434e-01,  2.0917e-01,\n",
      "         3.8494e-01, -8.6917e-02, -1.9187e-01,  2.5314e-02, -6.1164e-01,\n",
      "        -8.5325e-02, -5.9363e-01,  1.1971e+00, -9.6621e-03,  1.9447e-01,\n",
      "        -1.1552e-01,  1.2859e-01,  2.5271e-01,  1.5173e-01,  6.0097e-01,\n",
      "        -1.3192e-01,  1.3830e-01, -1.8187e-01,  4.0701e-01,  4.3928e-01,\n",
      "         7.6568e-01,  1.8167e-02,  1.5012e-02,  5.5587e-01,  3.2803e-01,\n",
      "        -7.6647e-02, -3.8164e-01, -6.1268e-02, -4.7847e-01,  2.4033e-01,\n",
      "        -7.5065e-02,  9.5463e-01, -7.3098e-02,  1.3976e-01, -9.1762e-02,\n",
      "        -4.4083e-01,  2.5709e-01, -6.8946e-01, -1.4206e-01,  2.5101e-02,\n",
      "         4.1167e-01, -3.8801e-01, -2.8201e-01,  1.1921e-02, -2.4845e-01,\n",
      "        -1.4863e-01, -4.9306e-03, -1.2944e+00, -1.4875e-01, -9.1363e-03,\n",
      "         4.5324e-01, -3.0668e-02, -1.6579e-01,  1.3517e-01, -2.7633e-02,\n",
      "         2.8317e-01,  4.3765e-02, -7.7783e-01, -4.0209e-01,  4.1316e-01,\n",
      "         2.3286e-02,  1.6126e-01, -9.3411e-02, -6.4906e-01,  8.3732e-01,\n",
      "         4.5597e-01,  4.2713e-01, -2.2890e-01, -1.4260e-01,  3.3747e-01,\n",
      "        -2.3359e-01,  2.6354e-01, -4.5050e-02, -2.7015e-01, -1.2008e-02,\n",
      "         3.4370e-01,  3.1910e-01,  3.3893e-01,  8.2905e-03,  1.0934e-02,\n",
      "         4.3586e-04,  7.6725e-02,  4.2784e-01,  3.2072e-02,  2.3165e-01,\n",
      "         3.4047e-01, -1.2395e-02, -2.9764e-01,  4.2205e-01, -5.3193e-01,\n",
      "        -4.8548e-01, -3.7029e-01, -3.5323e-02, -1.9615e-01,  3.0086e-01,\n",
      "        -3.1962e-01, -5.4824e-01, -1.1264e-01, -3.6150e-01, -2.3190e-01,\n",
      "         1.2414e-01,  4.0920e-02,  2.1717e-01, -5.0117e-01, -3.8968e-02,\n",
      "         1.8742e-01,  4.8352e-01, -4.2398e-01, -2.3921e-02, -4.2948e-01,\n",
      "         1.8999e-01,  2.4535e-01, -2.7377e-01, -1.2189e-01, -4.0847e-01,\n",
      "         1.6917e-01, -6.4787e-02, -1.2861e-01, -6.5466e-02,  2.5763e-02,\n",
      "         5.0322e-01, -7.5292e-02,  7.3468e-02,  5.2966e-02, -1.2985e+00,\n",
      "         3.8636e-01,  1.5968e-01, -2.1892e-02,  5.3254e-02,  1.6989e-01,\n",
      "        -6.1285e-02,  1.4282e-01, -3.8410e-02,  6.1048e-01,  3.7744e-01,\n",
      "        -7.2748e-02,  5.2014e-01,  2.2695e-01,  3.5550e-01,  5.5144e-01,\n",
      "        -1.3251e-01,  3.5291e-01,  2.4296e-01,  5.5571e-01])\n",
      "Query Artist: tensor([ 0.3943, -0.3300,  0.3245,  0.3198, -0.2134,  0.3004,  0.5638,  0.3561,\n",
      "         0.2294, -0.0058,  0.1126, -0.6514, -0.3770, -0.2043, -0.0300, -0.2782,\n",
      "         0.5047, -0.3481, -0.3225,  0.1589,  0.2919,  0.1727,  0.1905,  0.0913,\n",
      "        -0.4956, -0.1386, -0.3198,  0.1745, -0.1674, -0.3477,  0.0760,  0.2887,\n",
      "         0.2407,  0.2756, -0.2035, -0.0929,  0.0108, -0.1520, -0.1520,  0.2044,\n",
      "        -0.2612, -0.4710, -0.2423, -0.0027,  0.0736, -0.6110,  0.0534, -0.1368,\n",
      "         0.2706,  0.1420, -0.3132, -0.2282,  0.0694, -0.1909,  0.1801,  0.0835,\n",
      "         0.2715,  0.4540,  0.5477,  0.2939, -0.0422,  0.3148, -0.4349,  0.3839,\n",
      "         0.1062, -0.2213, -0.2228, -0.0700, -0.1814, -0.0966,  0.5934,  0.0476,\n",
      "         0.3337,  0.0793, -0.3973,  0.1467,  0.3882,  0.1235, -0.2916,  0.3787,\n",
      "        -0.0596,  0.0500, -0.1171, -0.2719,  0.0876, -0.0119, -0.1517, -0.0838,\n",
      "        -0.0498, -0.4274, -0.7490,  0.1946, -0.0082,  0.2317,  0.0227, -0.2352,\n",
      "         0.0386, -0.4559, -0.3822,  0.5516, -0.1498,  0.4394,  0.0869,  0.3025,\n",
      "        -0.3637, -0.1478,  0.3093, -0.2908, -0.1915,  0.1276,  0.1727, -0.1604,\n",
      "        -0.1670,  0.2286,  0.3532, -0.1066, -0.0906, -0.1713,  0.0245, -0.6238,\n",
      "         0.0134, -0.1776, -0.0096, -0.1175, -0.0815, -0.3683,  0.1607,  0.0893,\n",
      "        -0.1097, -0.1119, -0.1462, -0.0211,  0.2846,  0.2198, -0.2793, -0.0509,\n",
      "        -0.3988, -0.2097, -0.2149, -0.1966, -0.5309,  0.1136, -0.0984,  0.3221,\n",
      "         0.1416,  0.0421,  0.2168, -0.0276,  0.2954,  0.1723, -0.0652, -0.2672,\n",
      "         0.0472,  0.1043,  0.3069,  0.0012,  0.0675,  0.2533, -0.3528,  0.2688,\n",
      "         0.3306, -0.2691,  0.1118,  0.2313, -0.1522, -0.0726, -0.2497,  0.7900,\n",
      "         0.1976,  0.2143,  0.2958,  0.0992, -0.4310,  0.3889, -0.0620,  0.0176,\n",
      "         0.4143,  0.0013, -0.0493, -0.1854, -0.4144,  0.1626,  0.1193,  0.6119,\n",
      "        -0.3039, -0.1475,  0.1115,  0.3187, -0.2154, -0.3427, -0.0701, -0.0085,\n",
      "        -0.1645,  0.1116, -0.1602, -0.1447,  0.2870,  0.1607, -0.4999,  0.1653,\n",
      "        -0.0358, -0.2758,  0.1221, -0.3171,  0.0091, -0.2800,  0.2666,  0.5372,\n",
      "         0.2640,  0.4356,  0.1197,  0.1036, -0.0051,  0.0685,  0.0544, -0.0407,\n",
      "        -0.0976,  0.4146, -0.3132, -0.0341,  0.4383, -0.6864, -0.0348, -0.2556,\n",
      "         0.1615, -0.1773,  0.2408,  0.3390,  0.5554,  0.1577,  0.1014,  0.3571,\n",
      "         0.3768, -0.3388, -0.0585, -0.1386,  0.2915, -0.5347, -0.2277,  0.1771,\n",
      "         0.2204, -0.1023,  0.1817, -0.0407, -0.3120, -0.4848, -0.2269, -0.0169,\n",
      "        -0.3228,  0.1757,  0.2741,  0.3832, -0.7242, -0.0144,  0.0430, -0.1521,\n",
      "        -0.2531,  0.0165,  0.0623,  0.4710, -0.0401, -0.1465,  0.1178,  0.1298,\n",
      "        -0.0991,  0.0546, -0.0104, -0.0135, -0.0417,  0.3284, -0.0691,  0.0715,\n",
      "         0.3218, -0.4098,  0.0495, -0.1951, -0.4482, -0.0099, -0.1257, -0.1949,\n",
      "         0.2763, -0.2781, -0.1849,  0.0471, -0.0191,  0.1031, -0.0705, -0.1278,\n",
      "        -0.3209, -0.0116, -0.0141, -0.0049, -0.2354,  0.1039,  0.3276, -0.2157,\n",
      "        -0.1893,  0.5498, -0.3921, -0.1170, -0.4751, -0.3522,  0.0724, -0.2050,\n",
      "         0.2902, -0.1514, -0.3099, -0.4798,  0.4899,  0.5672,  0.1315,  0.0371,\n",
      "        -0.1727,  0.0707,  0.1318, -0.1254, -0.0197, -0.3834,  0.3048, -0.0940,\n",
      "        -0.3212,  0.1041, -0.2717,  0.0968,  0.2663,  0.2907, -0.0764, -0.1856,\n",
      "         0.1231, -0.1843, -0.0047, -0.3079, -0.2415,  0.0534,  0.1565,  0.2583,\n",
      "         0.2131,  0.2124, -0.1656, -0.2257,  0.0768,  0.1273, -0.1992, -0.5982,\n",
      "        -0.0214,  0.0302,  0.0140,  0.3103, -0.1310,  0.0021,  0.0586,  0.2805,\n",
      "        -0.2733, -0.4000,  0.2282, -0.0059,  0.5382, -0.0655, -0.1830,  0.0331,\n",
      "         0.5806,  0.2624, -0.0967,  0.3208, -0.4859,  0.1889,  0.3608, -0.0160,\n",
      "         0.1682,  0.0214,  0.0075, -0.2346,  0.0139,  0.0667, -0.0122,  0.0272,\n",
      "         0.3203,  0.2614, -0.1025,  0.3868,  0.5647, -0.2145,  0.6212, -0.0256])\n",
      "Query Playlist: tensor([-0.7064, -0.9495,  0.1814, -1.2626, -0.1109, -0.3619,  1.2588, -0.0077,\n",
      "         0.1253, -0.1776,  0.7709,  0.0577,  0.3640, -0.3362,  1.3711,  0.0318,\n",
      "        -0.1427,  0.0568,  0.0161, -0.1926,  0.1699, -0.8299, -0.1451, -0.4294,\n",
      "        -0.9459,  0.3160, -0.6364,  0.1609, -0.0653,  0.0767,  0.7645,  0.8878,\n",
      "         0.5863, -0.5793, -0.4259,  0.5275, -0.6579,  0.3694, -0.1994, -0.5845,\n",
      "        -0.3435, -0.7461, -0.0812, -0.2272, -0.0204, -0.0942, -0.3834,  0.7561,\n",
      "         0.0915,  0.7663, -0.1013, -0.6322, -0.3735,  0.4481, -0.2831,  0.0883,\n",
      "         0.1572,  0.8637,  0.6274,  0.6742, -0.8828, -0.1143, -0.9274,  1.0598,\n",
      "        -1.0790,  0.0855, -0.5942, -0.2108, -0.1314, -1.0514,  0.2594, -0.4179,\n",
      "         0.3733,  0.3651,  0.0487,  0.1330, -1.0585, -0.2777, -0.9433,  0.6435,\n",
      "         0.9925, -0.0953, -0.2040, -0.5921, -0.4618,  0.1697,  0.5962,  0.8081,\n",
      "         0.1182,  0.0588, -0.6257,  1.5419,  0.1071,  0.5483,  0.3203,  0.5333,\n",
      "        -0.7546, -2.0340, -0.0997,  2.4302, -0.2897,  0.4241, -0.0388,  0.6201,\n",
      "         0.4685, -1.0596, -0.1432,  0.1763,  0.3918,  0.7312, -0.2830,  0.1303,\n",
      "         0.4734, -0.4655, -0.4423, -0.6843,  0.3707, -0.4239,  0.5059, -0.8979,\n",
      "         0.9862, -0.2515, -0.7687, -0.2004,  0.4939,  0.0134,  0.7075,  0.7173,\n",
      "        -0.5843,  0.4813, -0.0327, -0.0051,  0.0052,  0.2451, -0.4199, -0.1266,\n",
      "        -0.9054, -0.1528,  0.0255, -0.6175, -0.7357, -0.1657, -0.4272, -0.7437,\n",
      "         0.2627,  0.2160, -0.3606, -0.6100, -0.4559,  0.4075,  0.2327, -0.3089,\n",
      "        -0.1112,  0.9677, -0.3146,  0.1138,  1.2064,  0.3475,  0.6307, -0.5865,\n",
      "        -0.5238, -0.5612,  1.3404,  0.0430, -0.1889, -0.8625,  0.0528,  0.3183,\n",
      "        -0.3682, -0.0631,  0.0042,  0.2987, -0.4784, -0.2332, -0.5262,  0.4433,\n",
      "         0.3570,  0.3824,  0.6316,  0.3624, -0.9856,  0.2944,  0.5447,  0.7782,\n",
      "        -0.9481,  0.1889,  0.5275,  0.1892,  0.2352, -0.0704,  0.3751, -1.2630,\n",
      "         0.7577, -0.1487,  0.1345, -0.0897, -0.0312,  0.3654,  0.6478, -0.4810,\n",
      "        -0.7112, -0.5504, -0.6044, -0.4544,  1.1804,  0.7466,  0.8666,  0.1007,\n",
      "         0.5267, -0.7661,  0.0826, -1.1487,  0.0825,  0.1679, -0.1143, -1.0134,\n",
      "        -0.1828, -0.2007, -1.0645,  0.4040, -1.1563, -0.0184, -0.3016, -0.7308,\n",
      "        -0.7431, -0.3515, -0.4373,  0.9092, -0.0753,  0.1691, -0.3960,  0.2966,\n",
      "         1.0482,  0.3843, -0.9327,  0.5770, -0.2064,  0.5184, -0.4338,  0.3768,\n",
      "         0.6368, -0.1744, -0.3512,  0.0341, -1.0151, -0.1464, -1.0336,  2.1146,\n",
      "        -0.0214,  0.2930, -0.1881,  0.1871,  0.4669,  0.2722,  1.0533, -0.2166,\n",
      "         0.2610, -0.3118,  0.7292,  0.7292,  1.3324,  0.0654,  0.0698,  1.0018,\n",
      "         0.5779, -0.1466, -0.6854, -0.1529, -0.8255,  0.4293, -0.0984,  1.6544,\n",
      "        -0.1334,  0.2622, -0.1545, -0.7961,  0.4504, -1.1595, -0.2477,  0.0678,\n",
      "         0.7158, -0.6584, -0.4759, -0.0513, -0.4373, -0.2805,  0.0124, -2.2335,\n",
      "        -0.2748, -0.0535,  0.7868, -0.0600, -0.2848,  0.2096, -0.0500,  0.4655,\n",
      "         0.1036, -1.3421, -0.6669,  0.6905,  0.0373,  0.2546, -0.1936, -1.1493,\n",
      "         1.4605,  0.8334,  0.7632, -0.4233, -0.2572,  0.5748, -0.3800,  0.4616,\n",
      "        -0.0872, -0.4865, -0.0560,  0.6033,  0.5353,  0.5909, -0.0161,  0.0365,\n",
      "         0.0253,  0.1143,  0.7694,  0.0642,  0.3975,  0.5688, -0.0314, -0.4592,\n",
      "         0.7445, -0.9519, -0.8326, -0.6374, -0.0780, -0.3629,  0.5416, -0.5751,\n",
      "        -0.9705, -0.2173, -0.5988, -0.4046,  0.2174,  0.0338,  0.3397, -0.8778,\n",
      "        -0.0443,  0.3326,  0.8176, -0.7177, -0.0184, -0.7297,  0.3334,  0.4290,\n",
      "        -0.4583, -0.1845, -0.6810,  0.3113, -0.1251, -0.2213, -0.1130,  0.0585,\n",
      "         0.8830, -0.1383,  0.1160,  0.0578, -2.2630,  0.6346,  0.2776, -0.0327,\n",
      "         0.1450,  0.3173, -0.1306,  0.2635, -0.0615,  1.0513,  0.6573, -0.1242,\n",
      "         0.9286,  0.3232,  0.6363,  0.9486, -0.2163,  0.6145,  0.4224,  0.9994])\n",
      "Top K Similar Embeddings: tensor([59, 51, 94, 85])\n",
      "Similarity Scores: tensor([0.9902, 0.9871, 0.9792, 0.9777])\n"
     ]
    }
   ],
   "source": [
    "def find_similar_embedding(query_genre, query_artist, query_playlist, database, model, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(query_genre.unsqueeze(0), query_artist.unsqueeze(0), query_playlist.unsqueeze(0))\n",
    "        \n",
    "        # Compute embeddings for all database entries\n",
    "        db_genres = torch.stack(database['genre_embedding'].tolist())\n",
    "        db_artists = torch.stack(database['artist_embedding'].tolist())\n",
    "        db_playlists = torch.stack(database['playlist_embedding'].tolist())\n",
    "        db_embeddings = model(db_genres, db_artists, db_playlists)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = torch.nn.functional.cosine_similarity(query_embedding, db_embeddings)\n",
    "        top_k_indices = torch.topk(similarities, k=top_k).indices\n",
    "        return top_k_indices, similarities[top_k_indices]\n",
    "\n",
    "# Example usage\n",
    "index_to_query = 1\n",
    "query_genre = df['genre_embedding'][index_to_query]\n",
    "query_artist = df['artist_embedding'][index_to_query]\n",
    "query_playlist = df['playlist_embedding'][index_to_query]\n",
    "\n",
    "print(\"Query Genre:\", query_genre)\n",
    "print(\"Query Artist:\", query_artist)\n",
    "print(\"Query Playlist:\", query_playlist)\n",
    "\n",
    "top_k_indices, scores = find_similar_embedding(query_genre, query_artist, query_playlist, df, model)\n",
    "# Remove index_to_query from the top_k_indices and also remove its score\n",
    "index_to_query_index = np.where(top_k_indices == index_to_query)[0][0]\n",
    "top_k_indices = np.delete(top_k_indices, index_to_query_index)\n",
    "scores = np.delete(scores, index_to_query_index)\n",
    "\n",
    "print(\"Top K Similar Embeddings:\", top_k_indices)\n",
    "print(\"Similarity Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"torch_model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the model and metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'output_dim': output_dim,\n",
    "}, os.path.join(model_dir, 'two_tower_model_torch.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44013002ed54d93b86de3fa8873076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cbb4adaa0f4ad2ae3c12409cf41d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/828414 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46d3a4e506f429fa22b0c47de162d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/828294 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3c0364504c42ff8be49054c1ad77a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/24364 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1208515/models/two_tower_model_torch/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'two_tower_model_torch', version: 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model registry handle\n",
    "mr = project.get_model_registry()\n",
    "model_registry = mr.get_model(\"two_tower_model_torch\", version=1) \n",
    "model_registry.delete()\n",
    "\n",
    "# Create the model metadata object\n",
    "torch_model = mr.torch.create_model(\n",
    "    name=\"two_tower_model_torch\",\n",
    "    metrics={'final_loss': total_loss},  # You can add your training metrics here\n",
    "    description=\"Two-tower model for music recommendations\",\n",
    "    version=1,\n",
    "    input_example={\n",
    "        'genre_embedding': genres[0].numpy().tolist(),\n",
    "        'artist_embedding': artists[0].numpy().tolist(),\n",
    "        'playlist_embedding': playlists[0].numpy().tolist()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the model to the registry\n",
    "torch_model.save(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
